{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14840890,"sourceType":"datasetVersion","datasetId":9492049}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nimport os\n\nsource_path = \"/kaggle/input/datasets/yuvrajsingh14/crack-or-noncrack\"\ndestination_path = \"/kaggle/working/dataset\"\n\nshutil.copytree(source_path, destination_path)\n\nprint(\"Dataset copied to working directory \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T16:46:35.389531Z","iopub.execute_input":"2026-02-17T16:46:35.390207Z","iopub.status.idle":"2026-02-17T16:48:58.011905Z","shell.execute_reply.started":"2026-02-17T16:46:35.390151Z","shell.execute_reply":"2026-02-17T16:48:58.011096Z"}},"outputs":[{"name":"stdout","text":"Dataset copied to working directory âœ…\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_path = \"/kaggle/working/dataset/train\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T16:52:42.803066Z","iopub.execute_input":"2026-02-17T16:52:42.803378Z","iopub.status.idle":"2026-02-17T16:52:42.807385Z","shell.execute_reply.started":"2026-02-17T16:52:42.803355Z","shell.execute_reply":"2026-02-17T16:52:42.806722Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os\nimport shutil\n\ntrain_path = \"/kaggle/working/dataset/train\"\n\nfor file in os.listdir(train_path):\n    if not file.endswith(\".png\"):\n        continue\n\n    number = int(file.split(\".\")[0])\n    src = os.path.join(train_path, file)\n\n    if 1 <= number <= 3068:\n        dst_folder = \"/kaggle/working/dataset/train/defect\"\n    elif 3069 <= number <= 6138:\n        dst_folder = \"/kaggle/working/dataset/train/no_defect\"\n    elif 6139 <= number <= 14138:\n        dst_folder = \"/kaggle/working/dataset/train/defect\"\n    elif 14139 <= number <= 22112:\n        dst_folder = \"/kaggle/working/dataset/train/no_defect\"\n    else:\n        continue\n\n    os.makedirs(dst_folder, exist_ok=True)\n    shutil.move(src, os.path.join(dst_folder, file))\n\nprint(\"Sorting Complete âœ…\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T16:52:55.421141Z","iopub.execute_input":"2026-02-17T16:52:55.421819Z","iopub.status.idle":"2026-02-17T16:52:56.397613Z","shell.execute_reply.started":"2026-02-17T16:52:55.421776Z","shell.execute_reply":"2026-02-17T16:52:56.396853Z"}},"outputs":[{"name":"stdout","text":"Sorting Complete âœ…\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(\"/kaggle/working/dataset/train\", transform=train_transform)\nval_dataset = datasets.ImageFolder(\"/kaggle/working/dataset/val\", transform=val_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T16:53:14.861071Z","iopub.execute_input":"2026-02-17T16:53:14.861770Z","iopub.status.idle":"2026-02-17T16:53:14.934251Z","shell.execute_reply.started":"2026-02-17T16:53:14.861736Z","shell.execute_reply":"2026-02-17T16:53:14.933524Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(len(os.listdir(\"/kaggle/working/dataset/train/defect\")))\nprint(len(os.listdir(\"/kaggle/working/dataset/train/no_defect\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T16:53:34.529067Z","iopub.execute_input":"2026-02-17T16:53:34.529832Z","iopub.status.idle":"2026-02-17T16:53:34.547348Z","shell.execute_reply.started":"2026-02-17T16:53:34.529782Z","shell.execute_reply":"2026-02-17T16:53:34.546517Z"}},"outputs":[{"name":"stdout","text":"11068\n11044\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using:\", device)\n\n# Strong Augmentation (important for generalization)\ntrain_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\ntrain_dataset = datasets.ImageFolder(\"/kaggle/working/dataset/train\", transform=train_transform)\nval_dataset = datasets.ImageFolder(\"/kaggle/working/dataset/val\", transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# EfficientNet\nmodel = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\nbest_acc = 0\n\nfor epoch in range(15):\n    model.train()\n    total_loss = 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Validation\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (preds == labels).sum().item()\n    \n    val_acc = correct / total\n    print(f\"Epoch {epoch+1}: Val Accuracy = {val_acc:.4f}\")\n    \n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), \"/kaggle/working/best_model.pth\")\n        print(\"âœ… Best model saved\")\n\nprint(\"ðŸ”¥ Best Validation Accuracy:\", best_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T16:55:00.564474Z","iopub.execute_input":"2026-02-17T16:55:00.564872Z","iopub.status.idle":"2026-02-17T17:18:33.112871Z","shell.execute_reply.started":"2026-02-17T16:55:00.564842Z","shell.execute_reply":"2026-02-17T17:18:33.112032Z"}},"outputs":[{"name":"stdout","text":"Using: cuda\nDownloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [00:00<00:00, 129MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Val Accuracy = 0.6449\nâœ… Best model saved\nEpoch 2: Val Accuracy = 0.6287\nEpoch 3: Val Accuracy = 0.6503\nâœ… Best model saved\nEpoch 4: Val Accuracy = 0.6061\nEpoch 5: Val Accuracy = 0.6768\nâœ… Best model saved\nEpoch 6: Val Accuracy = 0.6509\nEpoch 7: Val Accuracy = 0.7634\nâœ… Best model saved\nEpoch 8: Val Accuracy = 0.6293\nEpoch 9: Val Accuracy = 0.5914\nEpoch 10: Val Accuracy = 0.7018\nEpoch 11: Val Accuracy = 0.7063\nEpoch 12: Val Accuracy = 0.6153\nEpoch 13: Val Accuracy = 0.5845\nEpoch 14: Val Accuracy = 0.6801\nEpoch 15: Val Accuracy = 0.6190\nðŸ”¥ Best Validation Accuracy: 0.7633915359573838\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}